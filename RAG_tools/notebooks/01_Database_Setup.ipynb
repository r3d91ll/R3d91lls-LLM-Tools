{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Tools: Database Setup\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Welcome to the second notebook in our RAG Tools series! In this notebook, we'll set up Docker containers for our PostgreSQL database with pgvector extension and Neo4j graph database. We'll ensure both databases have accessible browser interfaces for easy management.\n",
    "\n",
    "By the end of this notebook, you'll have:\n",
    "1. Set up environment variables for database configuration\n",
    "2. Created a Docker Compose configuration for our databases\n",
    "3. Implemented utility classes for managing configurations and Docker containers\n",
    "4. Launched and verified our database containers\n",
    "\n",
    "## 2. Databases - PgVector and Neo4j\n",
    "\n",
    "In our RAG (Retrieval-Augmented Generation) system, we're using a combination of PgVector (PostgreSQL with vector extensions) and Neo4j. Let's understand why:\n",
    "\n",
    "1. **PgVector (PostgreSQL with vector extensions)**:\n",
    "   - Allows us to store and efficiently query high-dimensional vectors\n",
    "   - Crucial for embedding-based search and similarity comparisons in machine learning applications\n",
    "   - Provides fast similarity search capabilities, essential for our RAG system\n",
    "\n",
    "2. **Neo4j (Graph Database)**:\n",
    "   - Excels at representing and querying complex relationships between entities\n",
    "   - Allows us to model and query interconnected data more naturally than in traditional relational databases\n",
    "   - Useful for tasks like knowledge graph construction and traversal\n",
    "\n",
    "By combining these databases, we create a system that understands both semantic similarity (through vector embeddings in PgVector) and complex relationships (through graph structures in Neo4j). This combination is particularly powerful for tasks like code analysis, where we need to understand both the content of code (embedded into vectors) and the relationships between different code elements (represented as a graph).\n",
    "\n",
    "## 3. Environment Configuration\n",
    "\n",
    "Let's set up our environment variables by creating a `.env` file:\n",
    "\n",
    "1. Navigate to the `config/` directory in your project root.\n",
    "2. Create a new file named `.env` in this directory.\n",
    "3. Open the `.env` file in your preferred text editor.\n",
    "4. Copy and paste the following content into the file:\n",
    "\n",
    "```\n",
    "# PostgreSQL Configuration\n",
    "POSTGRES_DB=ragtools_db\n",
    "POSTGRES_USER=ragtools_user\n",
    "POSTGRES_PASSWORD=secure_postgres_password\n",
    "POSTGRES_HOST=localhost\n",
    "POSTGRES_PORT=5432\n",
    "\n",
    "# Neo4j Configuration\n",
    "NEO4J_AUTH=neo4j/secure_neo4j_password\n",
    "NEO4J_HOST=localhost\n",
    "NEO4J_HTTP_PORT=7474\n",
    "NEO4J_BOLT_PORT=7687\n",
    "\n",
    "# Docker Configuration\n",
    "POSTGRES_CONTAINER_NAME=ragtools_postgres\n",
    "NEO4J_CONTAINER_NAME=ragtools_neo4j\n",
    "DOCKER_NETWORK_NAME=ragtools_network\n",
    "```\n",
    "\n",
    "5. Save the file.\n",
    "\n",
    "**IMPORTANT**: Remember to update the passwords in this file with secure values before proceeding.\n",
    "\n",
    "The `.env` file plays a crucial role in our framework as a centralized repository for environment-specific configuration variables. As we progress through our project, we'll continually add new variables to this file, allowing us to easily manage and update our configuration settings without modifying our code.\n",
    "\n",
    "## 4. Docker Compose Configuration\n",
    "\n",
    "Now, let's create our `docker-compose.yml` file:\n",
    "\n",
    "1. In the same `config/` directory, create a new file named `docker-compose.yml`.\n",
    "2. Open the `docker-compose.yml` file in your text editor.\n",
    "3. Copy and paste the following content into the file:\n",
    "\n",
    "```yaml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  postgres:\n",
    "    image: ankane/pgvector\n",
    "    container_name: ${POSTGRES_CONTAINER_NAME}\n",
    "    environment:\n",
    "      POSTGRES_DB: ${POSTGRES_DB}\n",
    "      POSTGRES_USER: ${POSTGRES_USER}\n",
    "      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n",
    "    ports:\n",
    "      - \"${POSTGRES_PORT}:5432\"\n",
    "    volumes:\n",
    "      - ../db_data/postgres:/var/lib/postgresql/data\n",
    "    networks:\n",
    "      - ragtools_network\n",
    "\n",
    "  neo4j:\n",
    "    image: neo4j:latest\n",
    "    container_name: ${NEO4J_CONTAINER_NAME}\n",
    "    environment:\n",
    "      NEO4J_AUTH: ${NEO4J_AUTH}\n",
    "    ports:\n",
    "      - \"${NEO4J_HTTP_PORT}:7474\"\n",
    "      - \"${NEO4J_BOLT_PORT}:7687\"\n",
    "    volumes:\n",
    "      - ../db_data/neo4j:/data\n",
    "    networks:\n",
    "      - ragtools_network\n",
    "\n",
    "networks:\n",
    "  ragtools_network:\n",
    "    name: ${DOCKER_NETWORK_NAME}\n",
    "\n",
    "volumes:\n",
    "  postgres_data:\n",
    "  neo4j_data:\n",
    "```\n",
    "\n",
    "4. Save the file.\n",
    "\n",
    "This Docker Compose configuration sets up two services:\n",
    "1. A PostgreSQL service with the pgvector extension\n",
    "2. A Neo4j service\n",
    "\n",
    "Both services are configured to use volumes for data persistence, ensuring that your data remains intact even if the containers are stopped or removed.\n",
    "\n",
    "## 5. Configuration Utility\n",
    "\n",
    "To manage our configuration variables more efficiently, we'll create a `Config` class in a file named `config_utils.py`. Run the following code to create this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "config_utils_path = os.path.join('..', 'src', 'utils', 'config_utils.py')\n",
    "\n",
    "# Content of the config_utils.py file\n",
    "config_utils_content = '''\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        print(f\"Current working directory: {os.getcwd()}\")\n",
    "        \n",
    "        # Use an absolute path to the .env file\n",
    "        project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n",
    "        env_path = os.path.join(project_root, 'config', '.env')\n",
    "        print(f\"Looking for .env file at: {env_path}\")\n",
    "        \n",
    "        if os.path.exists(env_path):\n",
    "            print(f\".env file found at {env_path}\")\n",
    "            load_dotenv(env_path)\n",
    "            print(\"Environment variables after loading .env:\")\n",
    "            for key, value in os.environ.items():\n",
    "                if key.startswith(('POSTGRES_', 'NEO4J_', 'DOCKER_')):\n",
    "                    print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(f\".env file not found at {env_path}\")\n",
    "        \n",
    "        # Database configurations\n",
    "        self.POSTGRES_DB = os.getenv('POSTGRES_DB')\n",
    "        self.POSTGRES_USER = os.getenv('POSTGRES_USER')\n",
    "        self.POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "        self.POSTGRES_HOST = os.getenv('POSTGRES_HOST')\n",
    "        self.POSTGRES_PORT = os.getenv('POSTGRES_PORT')\n",
    "        \n",
    "        self.NEO4J_AUTH = os.getenv('NEO4J_AUTH')\n",
    "        self.NEO4J_HOST = os.getenv('NEO4J_HOST')\n",
    "        self.NEO4J_HTTP_PORT = os.getenv('NEO4J_HTTP_PORT')\n",
    "        self.NEO4J_BOLT_PORT = os.getenv('NEO4J_BOLT_PORT')\n",
    "        \n",
    "        # Docker configurations\n",
    "        self.POSTGRES_CONTAINER_NAME = os.getenv('POSTGRES_CONTAINER_NAME')\n",
    "        self.NEO4J_CONTAINER_NAME = os.getenv('NEO4J_CONTAINER_NAME')\n",
    "        self.DOCKER_NETWORK_NAME = os.getenv('DOCKER_NETWORK_NAME')\n",
    "        \n",
    "        print(\"Loaded configurations:\")\n",
    "        for attr, value in self.__dict__.items():\n",
    "            print(f\"{attr}: {value}\")\n",
    "\n",
    "    def get_postgres_connection_params(self):\n",
    "        return {\n",
    "            \"dbname\": self.POSTGRES_DB,\n",
    "            \"user\": self.POSTGRES_USER,\n",
    "            \"password\": self.POSTGRES_PASSWORD,\n",
    "            \"host\": self.POSTGRES_HOST,\n",
    "            \"port\": self.POSTGRES_PORT\n",
    "        }\n",
    "\n",
    "    def get_neo4j_connection_params(self):\n",
    "        return {\n",
    "            \"uri\": f\"bolt://{self.NEO4J_HOST}:{self.NEO4J_BOLT_PORT}\",\n",
    "            \"auth\": tuple(self.NEO4J_AUTH.split('/')) if self.NEO4J_AUTH else None\n",
    "        }\n",
    "'''\n",
    "\n",
    "# Write the content to the config_utils.py file\n",
    "with open(config_utils_path, 'w') as f:\n",
    "    f.write(config_utils_content)\n",
    "\n",
    "print(f\"Updated config_utils.py file created at: {config_utils_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create DockerComposeManager\n",
    "\n",
    "To manage our Docker environment more efficiently, let's create a Python utility called DockerComposeManager. This class will help us start, stop, and check the status of our Docker containers.\n",
    "\n",
    "First, let's create the file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the path to the src/utils directory\n",
    "utils_dir = os.path.join(current_dir, '..', 'src', 'utils')\n",
    "\n",
    "# Ensure the utils directory exists\n",
    "os.makedirs(utils_dir, exist_ok=True)\n",
    "\n",
    "# Construct the full path for the DockerComposeManager.py file\n",
    "docker_compose_manager_path = os.path.join(utils_dir, 'DockerComposeManager.py')\n",
    "\n",
    "# Content of the DockerComposeManager.py file\n",
    "docker_compose_manager_content = \"\"\"\n",
    "import subprocess\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class DockerComposeManager:\n",
    "    def __init__(self, compose_file_path):\n",
    "        self.compose_file_path = os.path.abspath(compose_file_path)\n",
    "        load_dotenv(dotenv_path=os.path.join(os.path.dirname(self.compose_file_path), '.env'))\n",
    "\n",
    "    def run_command(self, command):\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                f\"docker compose -f {self.compose_file_path} {command}\",\n",
    "                shell=True, check=True, capture_output=True, text=True\n",
    "            )\n",
    "            print(result.stdout)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing command: {e}\")\n",
    "            print(e.stderr)\n",
    "\n",
    "    def start_containers(self):\n",
    "        self.run_command(\"up -d\")\n",
    "\n",
    "    def stop_containers(self):\n",
    "        self.run_command(\"down\")\n",
    "\n",
    "    def show_container_status(self):\n",
    "        self.run_command(\"ps\")\n",
    "\"\"\"\n",
    "\n",
    "# Write the content to the DockerComposeManager.py file\n",
    "with open(docker_compose_manager_path, 'w') as f:\n",
    "    f.write(docker_compose_manager_content)\n",
    "\n",
    "print(f\"DockerComposeManager.py file created at: {docker_compose_manager_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `DockerComposeManager` class provides methods to start and stop containers, as well as check their status. It uses the `subprocess` module to run Docker Compose commands.\n",
    "\n",
    "## 7. Directory Structure for Persistent Databases\n",
    "\n",
    "To ensure data persistence for our databases, we need to create a specific directory structure. Here's how to set it up manually:\n",
    "\n",
    "1. In your project root directory, create a new directory called `db_data`.\n",
    "2. Inside the `db_data` directory, create two subdirectories:\n",
    "   - `postgres`\n",
    "   - `neo4j`\n",
    "\n",
    "Your directory structure should now look like this:\n",
    "\n",
    "```\n",
    "RAG_tools/\n",
    "├── config/\n",
    "│   ├── docker-compose.yml\n",
    "│   └── .env\n",
    "├── db_data/\n",
    "│   ├── postgres/\n",
    "│   └── neo4j/\n",
    "├── notebooks/\n",
    "├── src/\n",
    "│   └── utils/\n",
    "│       ├── config_utils.py\n",
    "│       └── DockerComposeManager.py\n",
    "└── tests/\n",
    "```\n",
    "\n",
    "This structure ensures that your database data will be stored persistently on your host machine, even when Docker containers are stopped or removed.\n",
    "\n",
    "## 8. Launch Docker Containers\n",
    "\n",
    "Now that we have our configuration utility and DockerComposeManager, let's use them to launch our Docker containers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import docker\n",
    "\n",
    "# Add the project root directory to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.utils.DockerComposeManager import DockerComposeManager\n",
    "from src.utils.config_utils import Config\n",
    "\n",
    "# Load configuration\n",
    "config = Config()\n",
    "\n",
    "# Create an instance of DockerComposeManager\n",
    "docker_compose_path = os.path.join(project_root, 'config', 'docker-compose.yml')\n",
    "docker_manager = DockerComposeManager(docker_compose_path)\n",
    "\n",
    "# Start the containers\n",
    "print(\"Starting Docker containers...\")\n",
    "docker_manager.start_containers()\n",
    "\n",
    "# Wait for a few seconds to allow containers to fully start\n",
    "time.sleep(10)\n",
    "\n",
    "# Check the status of the containers\n",
    "print(\"\\nChecking container status:\")\n",
    "docker_manager.show_container_status()\n",
    "\n",
    "# Verify that all expected containers are running\n",
    "client = docker.from_env()\n",
    "expected_containers = [config.POSTGRES_CONTAINER_NAME, config.NEO4J_CONTAINER_NAME]\n",
    "all_running = True\n",
    "\n",
    "for container_name in expected_containers:\n",
    "    try:\n",
    "        containers = client.containers.list(filters={'name': container_name})\n",
    "        if containers:\n",
    "            container = containers[0]\n",
    "            if container.status == 'running':\n",
    "                print(f\"{container_name} is running.\")\n",
    "            else:\n",
    "                print(f\"{container_name} is not running. Status: {container.status}\")\n",
    "                all_running = False\n",
    "        else:\n",
    "            print(f\"{container_name} not found.\")\n",
    "            all_running = False\n",
    "    except docker.errors.APIError as e:\n",
    "        print(f\"Error checking container {container_name}: {e}\")\n",
    "        all_running = False\n",
    "\n",
    "if all_running:\n",
    "    print(\"\\nAll containers are running successfully!\")\n",
    "else:\n",
    "    print(\"\\nSome containers are not running. Please check the logs for more information.\")\n",
    "\n",
    "# Print connection information\n",
    "print(\"\\nConnection Information:\")\n",
    "print(f\"PostgreSQL: {config.POSTGRES_HOST}:{config.POSTGRES_PORT}\")\n",
    "print(f\"Neo4j (HTTP): {config.NEO4J_HOST}:{config.NEO4J_HTTP_PORT}\")\n",
    "print(f\"Neo4j (Bolt): {config.NEO4J_HOST}:{config.NEO4J_BOLT_PORT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Verify Container Status and Database Connections\n",
    "\n",
    "Finally, let's verify our container status and test our database connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import psycopg2\n",
    "from neo4j import GraphDatabase\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add the project root directory to the Python path\n",
    "notebook_path = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_path, '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path: {sys.path}\")\n",
    "\n",
    "from src.utils.config_utils import Config\n",
    "\n",
    "def verify_database_connections():\n",
    "    config = Config()\n",
    "\n",
    "    def wait_for_postgres(max_attempts=5, delay=5):\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                conn_params = config.get_postgres_connection_params()\n",
    "                print(f\"Attempting to connect to PostgreSQL with params: {conn_params}\")\n",
    "                conn = psycopg2.connect(**conn_params)\n",
    "                conn.close()\n",
    "                print(\"Successfully connected to PostgreSQL\")\n",
    "                return True\n",
    "            except psycopg2.OperationalError as e:\n",
    "                print(f\"Attempt {attempt + 1}/{max_attempts}: PostgreSQL is not ready yet. Error: {e}. Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "        return False\n",
    "\n",
    "    def wait_for_neo4j(max_attempts=5, delay=5):\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                conn_params = config.get_neo4j_connection_params()\n",
    "                print(f\"Attempting to connect to Neo4j with params: {conn_params}\")\n",
    "                driver = GraphDatabase.driver(**conn_params)\n",
    "                with driver.session() as session:\n",
    "                    result = session.run(\"RETURN 1 AS x\")\n",
    "                    assert result.single()['x'] == 1\n",
    "                driver.close()\n",
    "                print(\"Successfully connected to Neo4j\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1}/{max_attempts}: Neo4j is not ready yet. Error: {e}. Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "        return False\n",
    "\n",
    "    postgres_ready = wait_for_postgres()\n",
    "    neo4j_ready = wait_for_neo4j()\n",
    "\n",
    "    if postgres_ready and neo4j_ready:\n",
    "        print(\"\\nAll database connections are successful!\")\n",
    "    else:\n",
    "        print(\"\\nSome database connections failed. Please check your configuration and container logs.\")\n",
    "\n",
    "    if postgres_ready:\n",
    "        try:\n",
    "            conn = psycopg2.connect(**config.get_postgres_connection_params())\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(\"SELECT * FROM pg_available_extensions WHERE name = 'vector';\")\n",
    "            result = cur.fetchone()\n",
    "            if result:\n",
    "                print(\"pgvector extension is available in PostgreSQL\")\n",
    "            else:\n",
    "                print(\"pgvector extension is not available. Please make sure it's installed correctly.\")\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking pgvector extension: {e}\")\n",
    "\n",
    "    print(\"\\nConnection Information:\")\n",
    "    print(f\"PostgreSQL: {config.POSTGRES_HOST}:{config.POSTGRES_PORT}\")\n",
    "    print(f\"Neo4j (HTTP): http://{config.NEO4J_HOST}:{config.NEO4J_HTTP_PORT}\")\n",
    "    print(f\"Neo4j (Bolt): bolt://{config.NEO4J_HOST}:{config.NEO4J_BOLT_PORT}\")\n",
    "\n",
    "verify_database_connections()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragtools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
